{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d70cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ba796",
   "metadata": {},
   "source": [
    "# Source and Data Description\n",
    "The data to be analyzed is published by the UC Irvine Machine Learning Repository.\n",
    "Originially the data was published by Tony Lindgren and Jonas Biteurs of Scania CV AB  in 2016.\n",
    "The downloadable zip file can be found on [UC Irvine's website](https://archive.ics.uci.edu/dataset/421/aps+failure+at+scania+trucks) and consists of three files:\n",
    "- aps_failure_description.txt\n",
    "- aps_failure_test_set.csv\n",
    "- aps_failure_training_set.csv\n",
    "\n",
    "\n",
    "Two labels are described with two classes:\n",
    "- positive class (failure related to APS)\n",
    "- negative class (failure not related to APS)\n",
    "\n",
    "## Cost\n",
    "A prediction model's performance is quantified with a Cost_1 = 10 for a false positive (failure predicted but truck working) and a false negative (truck with APS not recognized) with Cost_2 = 500.\n",
    "Total_cost = Cost_1*No_Instances + Cost_2*No_Instances\n",
    "\n",
    "## Dataset Overview\n",
    "The training set consists of 60000 examples in sum with 59000 negative and 1000 positive examples.\n",
    "The test set consists of 16000 examples.\n",
    "\n",
    "## Dataset Attributes\n",
    "There is a total of 171 Attributes with anonymized names. \n",
    "Single numerical values and 7 histograms (f.e. temperature bins) are in the data. \n",
    "Missing values are marked as \"na\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed9a02",
   "metadata": {},
   "source": [
    "# Goals and Intentions\n",
    "Based on the attributes and classification of the training data a prediction model is developed. This model should be able to divide the test set into classes. Finally the model can be tested by calculating the total cost of the model. The goal is to minimize the cost of the prediction model.\n",
    "In more technical terms the prediction model should identify faulty trucks with the information whether this is due to the APS or other technical failure. By figuring out the APS's role in the failure of the system the repairment process can be sped up and truck breakdowns can be prevented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172d91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/raw/aps_failure_training_set.csv\", header=14)\n",
    "test_df = pd.read_csv(\"../data/raw/aps_failure_test_set.csv\", header=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248335f",
   "metadata": {},
   "source": [
    "## First Look at the data\n",
    "In this section the dataframes are analyzed with respect to their datatypes and missing values.\n",
    "Open questions are:\n",
    "- What datatypes does the dataframe consist of?\n",
    "- How are missing values displayed?\n",
    "- How can the DataFrame be converted so that it is suitable for a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebda4507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  class  aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       " 0   neg   76698     na  2130706438    280      0      0      0      0      0   \n",
       " 1   neg   33058     na           0     na      0      0      0      0      0   \n",
       " 2   neg   41040     na         228    100      0      0      0      0      0   \n",
       " 3   neg      12      0          70     66      0     10      0      0      0   \n",
       " 4   neg   60874     na        1368    458      0      0      0      0      0   \n",
       " 5   neg   38312     na  2130706432    218      0      0      0      0      0   \n",
       " 6   neg      14      0           6     na      0      0      0      0      0   \n",
       " 7   neg  102960     na  2130706432    116      0      0      0      0      0   \n",
       " 8   neg   78696     na           0     na      0      0      0      0      0   \n",
       " 9   pos  153204      0         182     na      0      0      0      0      0   \n",
       " \n",
       "    ...   ee_002  ee_003   ee_004   ee_005   ee_006  ee_007  ee_008 ee_009  \\\n",
       " 0  ...  1240520  493384   721044   469792   339156  157956   73224      0   \n",
       " 1  ...   421400  178064   293306   245416   133654   81140   97576   1500   \n",
       " 2  ...   277378  159812   423992   409564   320746  158022   95128    514   \n",
       " 3  ...      240      46       58       44       10       0       0      0   \n",
       " 4  ...   622012  229790   405298   347188   286954  311560  433954   1218   \n",
       " 5  ...   388574  288278   900430   300412     1534     338     856      0   \n",
       " 6  ...      168      48       60       28        0       0       0      0   \n",
       " 7  ...   715518  384948   915978  1052166  1108672  341532  129504   7832   \n",
       " 8  ...   699290  362510  1190028  1012704   160090   63216   41202      4   \n",
       " 9  ...   129862   26872    34044    22472    34362       0       0      0   \n",
       " \n",
       "   ef_000 eg_000  \n",
       " 0      0      0  \n",
       " 1      0      0  \n",
       " 2      0      0  \n",
       " 3      4     32  \n",
       " 4      0      0  \n",
       " 5      0      0  \n",
       " 6      0      0  \n",
       " 7      0      0  \n",
       " 8      0      0  \n",
       " 9      0      0  \n",
       " \n",
       " [10 rows x 171 columns],\n",
       "   class  aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       " 0   neg      60      0          20     12      0      0      0      0      0   \n",
       " 1   neg      82      0          68     40      0      0      0      0      0   \n",
       " 2   neg   66002      2         212    112      0      0      0      0      0   \n",
       " 3   neg   59816     na        1010    936      0      0      0      0      0   \n",
       " 4   neg    1814     na         156    140      0      0      0      0      0   \n",
       " 5   neg     174     na          26     24      0      0     na     na     na   \n",
       " 6   neg   40202     na         640    606      0      0      0      0      0   \n",
       " 7   neg  120278     na  2130706432    256      0      0      0      0      0   \n",
       " 8   neg   14592      0  2130706438    162      0      0      0      0      0   \n",
       " 9   neg   28338     na  2130706432    238      0      0      0      0      0   \n",
       " \n",
       "    ...   ee_002  ee_003  ee_004  ee_005   ee_006  ee_007   ee_008 ee_009  \\\n",
       " 0  ...     1098     138     412     654       78      88        0      0   \n",
       " 1  ...     1068     276    1620     116       86     462        0      0   \n",
       " 2  ...   495076  380368  440134  269556  1315022  153680      516      0   \n",
       " 3  ...   540820  243270  483302  485332   431376  210074   281662   3232   \n",
       " 4  ...     7646    4144   18466   49782     3176     482       76      0   \n",
       " 5  ...       na      na      na      na       na      na       na     na   \n",
       " 6  ...   526218  239734  439556  374248   169096   53658    41054    320   \n",
       " 7  ...  1006722  459658  876356  689532   568540  500624  1006628  34820   \n",
       " 8  ...   105024   57398   49152   38256   243268  145144        0      0   \n",
       " 9  ...   357006  150056  264776  239282   140548   74750    32958     84   \n",
       " \n",
       "   ef_000 eg_000  \n",
       " 0      0      0  \n",
       " 1      0      0  \n",
       " 2      0      0  \n",
       " 3      0      0  \n",
       " 4      0      0  \n",
       " 5      0      0  \n",
       " 6      0      0  \n",
       " 7      0      0  \n",
       " 8      0      0  \n",
       " 9      0      0  \n",
       " \n",
       " [10 rows x 171 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10), test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc50b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 171 entries, class to eg_000\n",
      "dtypes: int64(1), object(170)\n",
      "memory usage: 78.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Columns: 171 entries, class to eg_000\n",
      "dtypes: int64(1), object(170)\n",
      "memory usage: 20.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.info(), test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1421e0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(class\n",
       " neg    59000\n",
       " pos     1000\n",
       " Name: count, dtype: int64,\n",
       " class\n",
       " neg    0.983333\n",
       " pos    0.016667\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"class\"].value_counts(), train_df[\"class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f0a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(class\n",
       " neg    15625\n",
       " pos      375\n",
       " Name: count, dtype: int64,\n",
       " class\n",
       " neg    0.976562\n",
       " pos    0.023438\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"class\"].value_counts(), test_df[\"class\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa01c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train_df.iloc[0,2]: na\n",
      "Type of na: \n",
      "<class 'str'>\n",
      "In the training set the following types can occur: \n",
      "{<class 'int'>, <class 'str'>}\n",
      "In the test set the following types can occur: \n",
      "{<class 'int'>, <class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "print(\"In train_df.iloc[0,2]: \" + train_df.iloc[0,2])\n",
    "print(\"Type of na: \"), print(type(train_df.iloc[0,2]))\n",
    "train_unique_types = set(type(v) for v in train_df.values.flatten())\n",
    "test_unique_types = set(type(v) for v in test_df.values.flatten())\n",
    "print(\"In the training set the following types can occur: \")\n",
    "print(train_unique_types)\n",
    "print(\"In the test set the following types can occur: \")\n",
    "print(test_unique_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b879f4ca",
   "metadata": {},
   "source": [
    "## Data insights\n",
    "Except from one int64 column, the data are all of type object. \n",
    "Since there are only strings and integers in the DFs, the object columns consist of those values.\n",
    "One of the strings is \"na\". In oder to see whether there are more strings than just the missing values, a conversion of the types and the resulting amount of NaNs is the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d5476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_train_df = train_df.copy()\n",
    "numeric_test_df = test_df.copy()\n",
    "\n",
    "for col in numeric_train_df.columns:\n",
    "    if col != \"class\":\n",
    "        numeric_train_df[col] = pd.to_numeric(numeric_train_df[col], errors=\"coerce\")\n",
    "        numeric_test_df[col] = pd.to_numeric(numeric_test_df[col], errors=\"coerce\")\n",
    "\n",
    "introduced_nan_fraction_train = numeric_train_df.isna().mean().sort_values(ascending=False)\n",
    "introduced_nan_fraction_test = numeric_test_df.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65bb124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(br_000    0.821067\n",
       " bq_000    0.812033\n",
       " bp_000    0.795667\n",
       " bo_000    0.772217\n",
       " ab_000    0.772150\n",
       " cr_000    0.772150\n",
       " bn_000    0.733483\n",
       " bm_000    0.659150\n",
       " bl_000    0.454617\n",
       " bk_000    0.383900\n",
       " dtype: float64,\n",
       " br_000    0.820562\n",
       " bq_000    0.811312\n",
       " bp_000    0.795063\n",
       " bo_000    0.773500\n",
       " ab_000    0.772687\n",
       " cr_000    0.772687\n",
       " bn_000    0.732062\n",
       " bm_000    0.659125\n",
       " bl_000    0.451625\n",
       " bk_000    0.380875\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduced_nan_fraction_train.head(10), introduced_nan_fraction_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04fa99",
   "metadata": {},
   "source": [
    "Now the fraction of NaN after conversion from the original DFs to numeric DFs is known. This needs to be compared to the original distribution of \"na\" occurences in the DFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f7f980c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(br_000    0.821067\n",
       " bq_000    0.812033\n",
       " bp_000    0.795667\n",
       " bo_000    0.772217\n",
       " ab_000    0.772150\n",
       "             ...   \n",
       " cj_000    0.005633\n",
       " ci_000    0.005633\n",
       " bt_000    0.002783\n",
       " aa_000    0.000000\n",
       " class     0.000000\n",
       " Length: 171, dtype: float64,\n",
       " br_000    0.820562\n",
       " bq_000    0.811312\n",
       " bp_000    0.795063\n",
       " bo_000    0.773500\n",
       " ab_000    0.772687\n",
       "             ...   \n",
       " cj_000    0.005375\n",
       " ci_000    0.005375\n",
       " bt_000    0.001750\n",
       " aa_000    0.000000\n",
       " class     0.000000\n",
       " Length: 171, dtype: float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_na_fraction_train = (train_df == \"na\").mean().sort_values(ascending=False)\n",
    "string_na_fraction_test = (test_df == \"na\").mean().sort_values(ascending=False)\n",
    "\n",
    "string_na_fraction_train, string_na_fraction_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04b6da",
   "metadata": {},
   "source": [
    "From the first glance the distribution of the NaN after conversion and the \"na\" before conversion seems to be the same. The difference in \"na\" distribution is now calculated. If this is 0 or close to 0 (due to rounding errors) that means, that the only strings in the DataFrame is \"na\" before and after conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd549b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(aa_000    0.0\n",
       " ab_000    0.0\n",
       " ac_000    0.0\n",
       " ad_000    0.0\n",
       " ae_000    0.0\n",
       " af_000    0.0\n",
       " ag_000    0.0\n",
       " ag_001    0.0\n",
       " ag_002    0.0\n",
       " ag_003    0.0\n",
       " dtype: float64,\n",
       " aa_000    0.0\n",
       " ab_000    0.0\n",
       " ac_000    0.0\n",
       " ad_000    0.0\n",
       " ae_000    0.0\n",
       " af_000    0.0\n",
       " ag_000    0.0\n",
       " ag_001    0.0\n",
       " ag_002    0.0\n",
       " ag_003    0.0\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_original_train = (train_df.drop(columns=\"class\") == \"na\").mean()\n",
    "missing_original_test = (test_df.drop(columns=\"class\") == \"na\").mean()\n",
    "missing_numeric_train = numeric_train_df.drop(columns=\"class\").isna().mean()\n",
    "missing_numeric_test = numeric_test_df.drop(columns=\"class\").isna().mean()\n",
    "\n",
    "missing_diff_train = (missing_original_train - missing_numeric_train).abs()\n",
    "missing_diff_test = (missing_original_test - missing_numeric_test).abs()\n",
    "\n",
    "missing_diff_train_sorted = missing_diff_train.sort_values(ascending=False)\n",
    "missing_diff_test_sorted = missing_diff_test.sort_values(ascending=False)\n",
    "\n",
    "missing_diff_train_sorted.head(10), missing_diff_test_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b018d8d",
   "metadata": {},
   "source": [
    "There is no difference between the amount of \"na\" and NaN after converting the original DFs to numeric DFs. This means that no missing values are added with the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f46b478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(float64    169\n",
       " object       1\n",
       " int64        1\n",
       " Name: count, dtype: int64,\n",
       " float64    169\n",
       " object       1\n",
       " int64        1\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_train_df.dtypes.value_counts(), numeric_test_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a68510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class']\n",
      "['class']\n",
      "['aa_000']\n",
      "['aa_000']\n",
      "0         76698\n",
      "1         33058\n",
      "2         41040\n",
      "3            12\n",
      "4         60874\n",
      "          ...  \n",
      "59995    153002\n",
      "59996      2286\n",
      "59997       112\n",
      "59998     80292\n",
      "59999     40222\n",
      "Name: aa_000, Length: 60000, dtype: int64\n",
      "0           60\n",
      "1           82\n",
      "2        66002\n",
      "3        59816\n",
      "4         1814\n",
      "         ...  \n",
      "15995    81852\n",
      "15996       18\n",
      "15997    79636\n",
      "15998      110\n",
      "15999        8\n",
      "Name: aa_000, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(numeric_train_df.select_dtypes(include=\"object\").columns.tolist())\n",
    "print(numeric_test_df.select_dtypes(include=\"object\").columns.tolist())\n",
    "print(numeric_train_df.select_dtypes(include=\"int64\").columns.tolist())\n",
    "print(numeric_test_df.select_dtypes(include=\"int64\").columns.tolist())\n",
    "print(numeric_train_df[\"aa_000\"])\n",
    "print(numeric_test_df[\"aa_000\"])\n",
    "string_na_fraction_train = (train_df == \"na\").mean().sort_values(ascending=True)\n",
    "string_na_fraction_test = (test_df == \"na\").mean().sort_values(ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10d010",
   "metadata": {},
   "source": [
    "The conversion to numeric DFs results in 169 columns of type float64, one column of type int64 and one object column.\n",
    "The object column is the \"class\" column with the entries \"neg\" or \"pos\", which is the goal value.\n",
    "The int64 column is \"aa_000\", which does not have a single \"na\" or NaN so its integers are converted into int64 automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ecd59",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "\n",
    "The key findings in the data understanding section are:\n",
    "- Anonymized data in train and test set\n",
    "- \"na\" represents missing data\n",
    "- Numeric conversion turns \"na\" to NaN\n",
    "- Numeric conversion results in 169 float64 columns (original dtype:object)\n",
    "- One column (\"aa_000\") is int64 (No \"na\" before conversion and all ints)\n",
    "- One column (\"class\") represents target values as strings (dtype:object)\n",
    "\n",
    "=> Next steps in 02_missing_data_strategy.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d3f95",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps_pred_main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
